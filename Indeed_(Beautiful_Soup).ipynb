{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8As/ACPAAdIxWVjLr4hnA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teena0401/Webscrapping-Indeed-Website/blob/main/Indeed_(Beautiful_Soup).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsIae7yrmm-L"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_indeed_url(search_job,search_location):\n",
        "  job = search_job.replace('','%+')\n",
        "  location = search_location.replace('','%+')\n",
        "  indeed_job_url = f'https://malaysia.indeed.com/jobs?q={job}&l={location}'\n",
        "  return indeed_job_url\n",
        "\n",
        "  https://www.jobstreet.com.my/en/job-search/data-engineer-jobs/\n",
        "  "
      ],
      "metadata": {
        "id": "-5iqqJX1ogHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_job_card(job_meta):\n",
        "  try: job_title = job_meta.find('h2',{'class':'jobTitle'}).get_text().lstrip('new\\n')\n",
        "  except: job_title = \"No Job Title Found\"\n",
        "  try: company_name = job_meta.find('span',{\"class\":\"companyName\"}).get_text()\n",
        "  except: company_name = \"No Company Name\"\n",
        "  try:company_location = job_meta.find('div',{'class':\"companyLocation\"}).get_text()\n",
        "  except: company_location = \"No Location\"\n",
        "  try:estimated_salary = job_meta.find('div',{'class':'metadata salary-snippet-container'}).get_text()\n",
        "  except: estimated_salary = \"No estimated Salary\"\n",
        "  return job_title, company_name, company_location, estimated_salary"
      ],
      "metadata": {
        "id": "YS_1o2agYXhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_job_description(job_desc_href):\n",
        "  try: \n",
        "    page = web_scrape_api_call(job_desc_href)\n",
        "    soup = BeautifulSoup(page.content,'html.parser')\n",
        "    job_desc = soup.find(id='jobDescriptionText')\n",
        "    job_desc=job_desc.text.replace('\\n','').replace('\\r','')\n",
        "  except: job_desc = 'No Job Description'\n",
        "  return job_desc"
      ],
      "metadata": {
        "id": "icC3bSKaak_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_job_page_meta(job_page_html):\n",
        "    page_soup = BeautifulSoup(job_page_html.text,'lxml')\n",
        "    df_columns = ['job_title','company_name','company_location','est_salary','job_href','job_desc']\n",
        "    obs_df = (pd.DataFrame(columns = df_columns))\n",
        "    for job in page_soup.find_all('div',{\"id\":\"mosaic-provider-jabcards\"}):\n",
        "      for href_post in job.find_all('a',href=True):\n",
        "        if href_post in job.find_all('a',href=True):\n",
        "           job_desc_href = 'https://www.indeed.com'+ str(href_post['href'])\n",
        "           job_desc = scrape_job_description(job_desc_href)\n",
        "           for job_meta in href_post.find_all('div',{\"class\":\"job_seen_beacon\"}):\n",
        "              job_title,company_name,company_location,estimated_salary =scrape_job_card(job_meta)\n",
        "              print(f'{job_title},{job_desc_href}')\n",
        "              job_dict ={'job_title':job_title,\n",
        "                          'company_name':[company_name],\n",
        "                            'est_salary': [estimated_salary],\n",
        "                             'job_href':[job_desc_href],\n",
        "                                 'job_desc':[job_desc]}\n",
        "              i_df = pd.DataFrame.from_dict(job_dict)\n",
        "              jobs_df = jobs_df.append(j_df,ignore_index=True)\n",
        "              return jobs_df\n"
      ],
      "metadata": {
        "id": "VyoBi_LxXJOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def job_loc_scrape_loop(job_list,loc_list,job_age):\n",
        "  date= dt.datetime.today().strftime('%Y-%m-%d')\n",
        "  for job in job_list:\n",
        "    for loc in loc_list:\n",
        "      print(f'Scraping:{job}{loc}')\n",
        "      indeed_url = make_indeed_url(job,loc,job_age)\n",
        "      indeed_response = web_scrape_api_call(indeed_url)\n",
        "      result_df = scrape_job_page_meta(indeed_response)\n",
        "      result_df['retrieve_date']=date\n",
        "      print('dumping to sql')\n",
        "      sql_dump(result_df,'data/jobs','indeed_jobs')\n",
        "      return none "
      ],
      "metadata": {
        "id": "4ySdv-1Wcpg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_dump(df,db,table):\n",
        "  con = sqlite3.connect(db)\n",
        "  df.to_sql(table,con,if_exists='append')\n",
        "  con.close()\n",
        "  "
      ],
      "metadata": {
        "id": "VzdoPDMlhQA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_scrape_api_call(url_to_scrape):\n",
        "  url = \"https://api.webscrapingapi.com/v1\"\n",
        "  params ={\"api_key\":WebScrapingAPIkey,\n",
        "           \"url\":url_to_scrape}\n",
        "  response = requests.request('GET',url,params =params)\n",
        "  return response"
      ],
      "metadata": {
        "id": "nkOdPtOEhhu9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}